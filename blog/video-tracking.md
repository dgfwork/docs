title: 视频跟踪
date: 2014-03-28 16:32:11
categories: 机器学习
tags:
---
下午老板叫去开会，心里就预感有事情要发生，该来的不该来的还是不可阻挡的来了。

从去年开始，我的研究方向就一直是视频跟踪，这也是我们实验室的传统课题。从一无所知，没有任何图像方面的基础，看论文被各种术语困住无法前行，一个基础一个基础的攻破，查阅了巨多的资料，看了十几篇论文，阅读、修改代码，反复研究，在几乎没有指导的情况下终于拨云见日、渐入佳境；理解了贝叶斯框架在视频跟踪中的应用，理解了粒子滤波、卡尔曼滤波、马尔可夫蒙特卡罗采样与视频跟踪的结合；看论文的速度也加快了。

期间得到周师兄的帮助，尤其在找论文、看论文方面给了很多有用的指导。周师兄写出的粒子滤波的 matlab 代码也让我对其有了更为形象的了解。

虽然这个方向前路如何我不得而知，科研的风险始终摆在那里，但学有所得的快乐是有的。

现在，我的方向是「视频大数据检索」了，但愿能用的上前面这些积累吧。

<!--more-->

在告别这个方向之际，我写这篇文章，梳理一下目前对视频跟踪的些许了解。

视频跟踪一般的方法是：在第一帧中用矩形框圈定目标 object，比如一个行人。在第二帧中，在不同的位置选择大小不同的矩形框，跟第一帧中框内的 object 比较，如果第二帧中哪个框中的内容跟第一帧框中的内容最相似，那么就选这个框中的内容为第二帧中跟踪到的 object。然后开始第三帧，以此类推。

这里面涉及两个问题：

1. 第二帧中怎么选择框？ 由于框的大小和位置都可以遍，如果用穷举法，那么几乎是无穷多个，这样效率就太低了。一般的做法是，在上一帧得到的 object附近洒粒子（如用高斯分布采样），以每个粒子为中心画框，大小可以不变，也可以根据高斯分布采样确定。这样就比穷举法要有效的多。这里的概念就是 proposal，提议分布。
2. 怎么确定某一帧中的某一框与第一帧中object 的相似度？这就是要确定要使用的外观模型了。一般可以用颜色的 HSV 直方图，然后通过巴氏距离确定相似度。

视频跟踪，本质上可以建模为 HMM。State 为 object 在某一帧中的位置；Observation 为颜色直方图；状态转移矩阵为上一帧中的 object 位置到这一帧中各位置的概率，即 proposal；发射概率即该位置产生这个颜色直方图的概率，即 likelihood。

在 HMM 上应用贝叶斯框架，视频跟踪问题就可以表示为：

![](http://ww3.sinaimg.cn/large/5e8cb366jw1eevl1f4jawj20f7019mx4.jpg)

这里编辑公式不方便，简单介绍一下上述公式的四项：

x 为 state，即这一帧（t+1时刻）中 object 在这个位置 x；y 为 observation，即观察到的这个 x 对应的框中的颜色直方图；第一项就是贝叶斯框架中的后验概率。

第二项是 HMM 中的发射概率，在贝叶斯中叫做 likelihood。

第三项是 HMM 中的转移概率矩阵，在贝叶斯中叫做 prior，先验概率。

第四项是上一帧（t时刻）的后验概率。

学过 HMM 的同学应该对这样的式子很熟悉。

注意到，这里面有积分，实际在用时是很难 analytically work out 的（当满足某些条件时，可以用卡尔曼滤波解决）。所以，视频跟踪领域中，基本上都是采用采样的方法来做。

关于采样，这是一个很大的话题，我前面作文介绍过。一般都是采用基于粒子滤波的方法，比较新的是使用基于粒子滤波的 MCMC 方法。粒子滤波和 MCMC 耗费了不少精力才弄懂，以后应该会专门作文介绍。

视频跟踪大概就是这么回事，具体的方法和例子，以后再介绍。

近年这个领域发表的论文，主要是解决视频跟踪中目标的运动和外观突变的问题。

这个领域值得关注的有 K.M.Lee，M.H.Yang等。比较新的方法有 incremental learning,sparse representation,patch,grid 等。

