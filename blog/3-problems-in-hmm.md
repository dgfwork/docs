title: 隐马尔可夫模型三个问题的求解(一)
date: 2013-10-17 09:18:47
categories: 机器学习
tags:
---
上一篇[《隐马尔可夫模型介绍》](http://zipperary.com/2013/10/15/an-introduction-to-hmm/)中讲解了马尔可夫假设和隐马尔可夫模型 HMM，并提到了 HMM 中的三个基本问题，但没有展开讨论其求解。本篇就此做出解答。

本文主要参考[《HMM 学习最佳范例》](http://www.52nlp.cn/category/hidden-markov-model/page/4)。

先回顾一下，上节我们就硬币的例子提出了三个问题：

1. 给定上述模型，观察到的结果（硬币的正反面）为O={H，T，H}的概率是多少？
2. 若给定上述的观察结果，那么最可能的状态序列（硬币序号）是什么？
3. A、B、π未知的情况下，如何根据 O 得到它们？

问题一是个估算问题，P（O|λ），可用向前算法和向后算法解决；

问题二是根据观察序列反向找出最可能的状态序列，是个解码问题，P（O,q|λ），q 是某状态，最常用的是 Viterbi算法；

问题三实际上是个参数估计或求解的问题，或者说是个学习问题，通过训练一步步优化参数，找到使得P（O|λ）最大的那个参数，最常用的是 Baum-Welch算法。

---
###例子

这里，我们提出一个更加恰当的例子：

有一个宅男，不爱出门，也不愿看看窗户外面的世界。但他有个特殊的习惯，通过观察海藻来推测外面的天气情况。天气一共有3种情况 S：（晴天、多云、雨天）；海藻一共有4种情况V：（干、稍干、潮湿、湿润）。海藻的情况是宅男直接观察到的，而天气的情况并没有直接观察到，而是隐藏状态，是他推测出来的。其关系如图所示：

![](http://ww3.sinaimg.cn/large/5e8cb366jw1e9nxfm6fm5j20bu07dq3k.jpg)

<!--more-->

另外，我们给出其他三个条件：

天气的状态转移矩阵A：

![](http://ww1.sinaimg.cn/large/5e8cb366jw1e9nxie43xtj20bw046gls.jpg)

天气的初始概率向量π：

![](http://ww1.sinaimg.cn/large/5e8cb366jw1e9nxjfricdj205d01swea.jpg)

天气状态和海藻观察情况的混淆矩阵 B：

![](http://ww2.sinaimg.cn/large/5e8cb366jw1e9nxk60arrj20af03o3yj.jpg)

现在，这个 HMM 已经构建好了，如上一节所说，是一个五元组λ=（S，V，A，B，π）。

我们使用一个隐马尔科夫模型（HMM）对这个例子建模。这个模型包含两组状态集合和三组概率集合：

- 隐藏状态：一个系统的（真实）状态，可以由一个马尔科夫过程进行描述（例如，天气）。
- 观察状态：在这个过程中‘可视’的状态（例如，海藻的湿度）。
- pi向量：包含了（隐）模型在时间t=1时一个特殊的隐藏状态的概率（初始概率）。
- 状态转移矩阵：包含了一个隐藏状态到另一个隐藏状态的概率
- 混淆矩阵：包含了给定隐马尔科夫模型的某一个特殊的隐藏状态，观察到的某个观察状态的概率。

###评估问题：前向算法

给定λ，要计算某个观察序列 O的概率，最不费脑子的办法就是**穷举法**。

![](http://ww4.sinaimg.cn/large/5e8cb366jw1e9nxtk7wpkj20be05cjro.jpg)

如图，若求序列（dry,damp,soggy）的概率，只要把每种可能的状态序列都算一下概率，最后相加即可。一共有3**3=27种。

总的概率是：Pr(dry,damp,soggy | HMM) = Pr(dry,damp,soggy | sunny,sunny,sunny) + Pr(dry,damp,soggy | sunny,sunny ,cloudy) + Pr(dry,damp,soggy | sunny,sunny ,rainy) + . . . . Pr(dry,damp,soggy | rainy,rainy ,rainy)

其中每项的求解很简单，利用初始状态向量π、状态转移矩阵 A 和混淆矩阵 B，通过相乘就能得到。

可以看到，这种做法的代价是比较昂贵的，省了脑力就会相应的耗费体力，上帝是公平的。

下面提出一种颇费脑细胞，但代价比较小的算法：**前向算法**。

首先，定义**局部概率**这个概念：它是到达上图网格中间某个状态的概率，它是所有到达这个状态的可能路径的概率求和的结果。

例如，对于 t=2时Cloudy的局部概率：

![](http://ww4.sinaimg.cn/large/5e8cb366jw1e9ny3n70dyj2098053glq.jpg)

有三个路径，分别计算每条路径的概率，再求和即可。相信聪明的你已经想到，我们正是利用**递推**的方式来求解最后结果：

首先计算 t=1的情况，然后就算 t=i 的情况（利用 t=i-1），最后得出最末时刻的概率。

![](http://ww2.sinaimg.cn/large/5e8cb366jw1e9ny8rzqfkj204x00x743.jpg)

其中，j 表示三个天气状态中的某一种；α1(j)表示 t=1时，天气状态为 j 时，得到观察为 k1的概率；等式的右边，表示初始状态下某天气的概率乘以该天气下得到 k1观察的概率。

![](http://ww4.sinaimg.cn/large/5e8cb366jw1e9ny9fibxsj207d01g745.jpg)

这个式子中加入了状态转移矩阵的元素，就是 aij，用来递推计算，总的形式和上式一致。

![](http://ww2.sinaimg.cn/large/5e8cb366jw1e9nyb4eyafj205p01jglg.jpg)

最后所求概率，是一个加和，由于递推结束，不需要状态转移矩阵了。

[这里](http://www.52nlp.cn/hmm-learn-best-practices-five-forward-algorithm-5)有一个实际的计算过程可供参考。

为什么叫「前向算法」呢？从上面可以看出，这个算法的本质，是根据前t时的情况计算t+1时的情况，是一个逐渐向前推进的过程。

时间有限，今天先写这些，预告：

解码问题：Viterbi 算法

学习问题：Baum-Welch 算法