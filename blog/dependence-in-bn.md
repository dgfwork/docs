title: 贝叶斯网络中的依赖关系
date: 2014-06-24 22:48:50
categories: 机器学习
tags:
---
贝叶斯网络（Bayesian Network，简称 BN）是机器学习中最重要的工具之一，它以贝叶斯规则（Bayesian Rule）为基础，并为马尔可夫模型奠定了基础。

简单来说，贝叶斯网络就是一个有向无环图。节点 node 表示变量，弧 arc 表示依赖关系。比如下图：

![](http://ww1.sinaimg.cn/large/5e8cb366jw1ehple2py1lj206u03kdft.jpg)

「Sprinkler」是洒水器的意思。这三个变量代表三种事件。下雨和洒水器都能影响草地湿度，而下雨又可以影响洒水器是否洒水。三个变量的依赖关系如图所示。

在 BN 中，有些 node 是可以观察到的observable，有些是无法观察到的 hidden。比如下雨和草地湿可以观察到，洒水器是否洒水了是无法观测得到的。对于一个 BN，我们可以求所有变量的联合概率，也可以求某个隐节点的后验概率。前提是我们已经得到了这个 BN 所需要的参数：每个 arc 所代表的条件概率。

不过我今天要讲的东西并不是这些，而是条件依赖关系，这类概念让我颇费脑子。

<!--more-->


下面通过两种结构来讨论四种依赖关系。

###条件独立

先看图：

![](http://ww1.sinaimg.cn/large/5e8cb366jw1ehpln4jn8yj203f03k0sl.jpg)

C 表示 cancer，取值空间是{C,-C} ；T1 和 T2表示两个检测结果，取值空间是{+,-}。每个箭头代表的条件概率表已知。

1. 已知 C，那么 T1, T2是否独立？ 假如知道这个病人实际上患癌症，在估计 T2的时候，知道「T1是+」与否对这个估计有影响吗？其实是没有影响的。T1和 T2相当于对 C 做了两次独立观测。在 C 已知的情况下，T1,T2独立，因此属于条件独立。用全概率公式计算一下会更加的一目了然，会发现计算 P(T2)的过程中并没有涉及到 T1.
2. 若 C 未知，那么 T1,T2是否独立。假如 T1为+，那么我们会认为 C 很有可能也是+，进而认为 T2同样取+的概率会提升。因此 T1,T2不独立。如果有兴趣，可以计算一下 P(T2=+ | T1=+)和 P(T2=+)，可以看到分别是0.2301和0.207，前者大。如图：

![](http://ww1.sinaimg.cn/large/5e8cb366jw1ehpm233shmj20kp0bc0uf.jpg)


###条件依赖

先看例子：

![](http://ww3.sinaimg.cn/large/5e8cb366jw1ehpm762vsoj204003mmx1.jpg)

S: sunny; R: raise of salary; H: happiness.条件概率表已知。

1. 若 H 未知，则P(R | S) = P(R)，即两者独立。直白的解释就是：我朋友并不知道我是否高兴，只看到天气是晴朗的，他能推测我是否涨了工资吗？当然不能。
2. 若 H 已知，这时候出现一个有趣的现象，叫 explain away.朋友看到我很高兴，又看了看天，发现是个大晴天，他就会认为我的高兴应该是由于天晴的缘故，不大可能是由于涨工资的原因；朋友若看到我高兴，同时又看到天气很糟糕，那么他会认为我很可能是涨工资了。也就是说，在已知 H 的情况下，对 S 的观测影响到了对 R 的估计，说明 S 和 R 是条件依赖的。

掌握了上述四种情况的依赖关系，那么整个 BN 中任意两个节点的依赖关系就可以知道了。

好，主要内容讲完了，顺便说一下，BN 中最重要的 basics 是 chain rule, Bayesian Rule 和 total probability，在计算中会大量使用；最重要的参数是每个 arc 的条件概率表。BN 可以做分类器，node 为特征向量中的各分量，并有一个 node 表示label，学习的过程就是求得上述参数。BN 较其他分类器的优势在于考虑了各特征之间的依赖关系。